# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
import nemo.collections.asr as nemo_asr
import torch
import librosa

class PyTorch_NeMo_Parakeet_RNNT_0_6B(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # NeMo models from_pretrained don't support device_map, so we move the model to the device manually.
        multi_gpu = self.config.pop("_multi_gpu", False)

        self.model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(model_name="nvidia/parakeet-rnnt-0.6b")
        self.model.to(torch.device(device))
        self.model.eval()

        self.sampling_rate = self.config.get('sampling_rate', 16_000)

    def preprocess(self, input_audios):
        # The NeMo transcribe method directly accepts a list of audio file paths.
        # No further preprocessing is required in this step.
        return input_audios

    def predict(self, model_input):
        # model_input is a list of audio file paths.
        # The transcribe method handles loading, preprocessing, and decoding.
        return self.model.transcribe(paths2audio_files=model_input)

    def postprocess(self, model_output):
        # The transcribe method returns a list of final transcriptions.
        # No further postprocessing is needed.
        return model_output
