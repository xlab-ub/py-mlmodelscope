# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from PIL import Image
import pytesseract
import torch

class PyTorch_Transformers_LiLT_Document_QA(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        model_id = "TusharGoel/LiLT-Document-QA"
        self.tokenizer = AutoTokenizer.from_pretrained(model_id, add_prefix_space=True)
        self.model = AutoModelForQuestionAnswering.from_pretrained(model_id)

        if not multi_gpu:
            self.model.to(device)
        self.device = device

    def preprocess(self, input_document_images_and_questions):
        all_questions, all_words, all_boxes = [], [], []

        for image_path, question in input_document_images_and_questions:
            image = Image.open(image_path).convert("RGB")
            width, height = image.size
            
            ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)
            
            words, boxes = [], []
            for i in range(len(ocr_data["text"])):
                if ocr_data['text'][i].strip():
                    words.append(ocr_data['text'][i])
                    x0 = ocr_data['left'][i]
                    y0 = ocr_data['top'][i]
                    w = ocr_data['width'][i]
                    h = ocr_data['height'][i]
                    x1 = x0 + w
                    y1 = y0 + h
                    normalized_box = [
                        int(1000 * x0 / width),
                        int(1000 * y0 / height),
                        int(1000 * x1 / width),
                        int(1000 * y1 / height)
                    ]
                    boxes.append(normalized_box)
            
            all_questions.append(question)
            all_words.append(words)
            all_boxes.append(boxes)

        encoding = self.tokenizer(all_questions, all_words, boxes=all_boxes, padding="max_length", truncation=True, return_tensors="pt")
        encoding = {k: v.to(self.device) for k, v in encoding.items()}
        
        return (encoding, all_words)

    def predict(self, model_input):
        encoding, all_words = model_input
        outputs = self.model(**encoding)
        return (outputs, encoding, all_words)

    def postprocess(self, model_output):
        outputs, encoding, all_words = model_output

        start_logits = outputs.start_logits
        end_logits = outputs.end_logits

        start_indices = torch.argmax(start_logits, dim=-1)
        end_indices = torch.argmax(end_logits, dim=-1)

        answers = []
        for i in range(len(start_indices)):
            start_idx = start_indices[i].item()
            end_idx = end_indices[i].item()
            
            word_ids = encoding.word_ids(i)
            
            start_word_idx = word_ids[start_idx]
            end_word_idx = word_ids[end_idx]

            if start_word_idx is not None and end_word_idx is not None and start_word_idx <= end_word_idx:
                current_words = all_words[i]
                answer = " ".join(current_words[start_word_idx : end_word_idx + 1])
                answers.append(answer)
            else:
                answers.append("")

        return answers
