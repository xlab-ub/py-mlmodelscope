# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import LayoutDetection
import json

class PyTorch_PaddleOCR_PP_DocBlockLayout(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        # Note: paddleocr manages its own device settings. 'device' and 'multi_gpu' are kept for API compatibility.
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        # Initialize the LayoutDetection model from paddleocr
        self.model = LayoutDetection(model_name="PaddlePaddle/PP-DocBlockLayout")

        # Get prediction parameters from config with defaults from the model card example
        self.batch_size = self.config.get('batch_size', 1)
        self.layout_nms = self.config.get('layout_nms', True)

    def preprocess(self, input_images):
        # The paddleocr model directly accepts a list of image paths.
        # No further preprocessing is needed.
        return input_images

    def predict(self, model_input):
        # model_input is a list of image paths
        # The predict method returns a list of LayoutResult objects
        return self.model.predict(model_input, batch_size=self.batch_size, layout_nms=self.layout_nms)

    def postprocess(self, model_output):
        # The model output is a list of LayoutResult objects.
        # Each LayoutResult object contains the detected layout boxes for one image.
        # We convert the data from each result object into a JSON string for a standardized output.
        results = []
        for res in model_output:
            # res.data is a list of dictionaries, where each dictionary represents a detected box.
            # Example: [{'cls_id': 0, 'label': 'Region', 'score': 0.97, 'coordinate': [x1, y1, x2, y2]}]
            results.append(json.dumps(res.data))
        return results
