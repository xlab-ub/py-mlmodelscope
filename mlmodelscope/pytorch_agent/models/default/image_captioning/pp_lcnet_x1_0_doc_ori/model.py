# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import DocImgOrientationClassification
from PIL import Image
import numpy as np

class PyTorch_PaddleOCR_DocImgOrientationClassification(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        # Device and multi_gpu are handled by paddleocr's init, but we keep the boilerplate
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        # The paddleocr library handles model downloading and caching.
        # The device parameter is passed during initialization.
        # e.g., device='gpu:0' for cuda, device='cpu' for cpu
        paddle_device = 'gpu:0' if device == 'cuda' else 'cpu'

        self.model = DocImgOrientationClassification(
            model_name="PaddlePaddle/PP-LCNet_x1_0_doc_ori",
            device=paddle_device
        )

        self.batch_size = self.config.get('batch_size', 1)

    def preprocess(self, input_images):
        # The paddleocr model can take image paths directly.
        # We will pass the list of paths to the predict method.
        return input_images

    def predict(self, model_input):
        # The model_input is a list of image paths from the preprocess step.
        # The model's predict method handles batching internally.
        return self.model.predict(input=model_input, batch_size=self.batch_size)

    def postprocess(self, model_output):
        # The model output is a list of result objects.
        # Each object contains a dictionary with the key 'res'.
        # We extract the 'label_names' which contains the orientation as a string.
        # e.g., {'res': {'label_names': ['180']}}
        captions = []
        for res_obj in model_output:
            # The result object has a 'res' attribute which is a dictionary
            if hasattr(res_obj, 'res') and isinstance(res_obj.res, dict):
                label_names = res_obj.res.get('label_names', [])
                if label_names:
                    captions.append(str(label_names[0]).strip())
                else:
                    captions.append("unknown orientation")
            else:
                captions.append("unknown orientation")
        return captions
