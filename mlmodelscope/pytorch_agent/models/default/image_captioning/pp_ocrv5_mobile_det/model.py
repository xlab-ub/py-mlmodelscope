# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import TextDetection
import numpy as np

class PyTorch_PaddleOCR_PP_OCRv5_Mobile_Det(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # multi_gpu is not directly supported by the paddleocr library in this way, but we keep the boilerplate
        multi_gpu = self.config.pop("_multi_gpu", False)

        # The paddleocr library handles device mapping differently.
        # It expects 'cpu', 'gpu', or 'gpu:0', etc.
        # We will map 'cuda' to 'gpu' for compatibility.
        paddle_device = 'gpu' if device == 'cuda' else 'cpu'

        # This model is loaded by its short name via the paddleocr library, not from Hugging Face directly.
        # The library handles the download and caching of the model weights.
        # The model identifier 'PaddlePaddle/PP-OCRv5_mobile_det' is informational; the library uses 'PP-OCRv5_mobile_det'.
        self.model = TextDetection(model_name="PP-OCRv5_mobile_det", device=paddle_device)

        self.batch_size = self.config.get('batch_size', 1)

    def preprocess(self, input_images):
        # The paddleocr model's predict method directly accepts image file paths.
        # Therefore, this preprocessing step is a pass-through, returning the list of paths.
        return input_images

    def predict(self, model_input):
        # The model_input is a list of image paths from the preprocess step.
        # The predict method handles image loading, preprocessing, and inference internally.
        return self.model.predict(input=model_input, batch_size=self.batch_size)

    def postprocess(self, model_output):
        # The model output is a list of result objects from the paddleocr library.
        # Each object contains detection polygons and scores for an image.
        # This is a text detection model, not a captioning model, so we format the detection results.
        results = []
        for res_obj in model_output:
            # The raw data is in the 'res' attribute of the result object
            raw_result = res_obj.res
            # Convert numpy arrays to lists for JSON serialization
            polygons = raw_result['dt_polys'].tolist() if isinstance(raw_result['dt_polys'], np.ndarray) else raw_result['dt_polys']
            scores = raw_result['dt_scores']
            results.append({'polygons': polygons, 'scores': scores})
        return results
