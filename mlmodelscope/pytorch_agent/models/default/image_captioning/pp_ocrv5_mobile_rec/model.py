# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import TextRecognition

class PyTorch_PaddleOCR_PP_OCRv5_Mobile_Rec(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # multi_gpu is not directly supported by the simple TextRecognition interface
        multi_gpu = self.config.pop("_multi_gpu", False)

        # The paddleocr library uses a boolean flag for GPU usage.
        use_gpu_flag = True if device == "cuda" else False

        # Initialize the TextRecognition model from paddleocr
        # This will download the model weights if not cached
        self.model = TextRecognition(model_name="PaddlePaddle/PP-OCRv5_mobile_rec", use_gpu=use_gpu_flag)

    def preprocess(self, input_images):
        # The paddleocr predict method directly accepts a list of image paths.
        # No special preprocessing is needed here, just pass the list of paths.
        return input_images

    def predict(self, model_input):
        # The model's predict method handles one image at a time.
        # We iterate through the batch of image paths and collect the results.
        results = []
        for image_path in model_input:
            # The output for a single image is a list of result objects.
            result = self.model.predict(input=image_path)
            results.append(result)
        return results

    def postprocess(self, model_output):
        predictions = []
        # model_output is a list of lists, where each inner list contains result objects for one image.
        # e.g., [[res_obj_img1], [res_obj_img2], ...]
        for image_results in model_output:
            if image_results:
                # A single image might have multiple text lines detected by a full OCR pipeline,
                # but this is a text line recognizer. We join any results with a space for robustness.
                recognized_text = " ".join([res.res['rec_text'] for res in image_results])
                predictions.append(recognized_text.strip())
            else:
                # Handle cases where no text is detected in an image.
                predictions.append("")
        return predictions
