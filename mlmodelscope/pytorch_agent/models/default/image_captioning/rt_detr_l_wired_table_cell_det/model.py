# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import TableCellsDetection
from PIL import Image
import json

class PaddleOCR_RT_DETR_L_Wired_Table_Cell_Detection(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # paddleocr uses a boolean flag for GPU
        use_gpu = True if device == "cuda" else False

        # This model is from the paddleocr library, not Hugging Face transformers
        # The model_name parameter corresponds to the Hugging Face identifier
        self.model = TableCellsDetection(model_name="PaddlePaddle/RT-DETR-L_wired_table_cell_det", use_gpu=use_gpu)

        # Get prediction parameters from config with defaults from the model card
        self.threshold = self.config.get('threshold', 0.3)
        self.batch_size = self.config.get('batch_size', 1)

    def preprocess(self, input_images):
        # The paddleocr library's predict method directly accepts image file paths.
        # Therefore, no preprocessing is needed here; we just pass the paths along.
        return input_images

    def predict(self, model_input):
        # The model_input is a list of image file paths from the preprocess step.
        return self.model.predict(model_input, threshold=self.threshold, batch_size=self.batch_size)

    def postprocess(self, model_output):
        # The model output is a list of dictionary objects, one for each image.
        # Each dictionary contains the bounding box information.
        # We extract the list of boxes for each image.
        processed_results = []
        for result in model_output:
            # The result object is a dictionary, e.g., {'res': {'boxes': [...]}}
            boxes = result.get('res', {}).get('boxes', [])
            processed_results.append(boxes)
        return processed_results
