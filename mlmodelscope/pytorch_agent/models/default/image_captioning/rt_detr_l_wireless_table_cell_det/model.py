# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from paddleocr import TableCellsDetection
from PIL import Image
import json

class PyTorch_PaddleOCR_RT_DETR_L_Table_Cell_Detection(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        # Note: paddleocr handles device management internally or via environment variables.
        # The _device and _multi_gpu flags are acknowledged but may not be directly used by this specific model wrapper.
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        # This model is from the paddleocr library, not Hugging Face transformers.
        self.model = TableCellsDetection(model_name="PaddlePaddle/RT-DETR-L_wireless_table_cell_det")
        
        # Get prediction parameters from config, based on the model card's usage example.
        self.threshold = self.config.get('threshold', 0.3)

    def preprocess(self, input_images):
        # The paddleocr model's predict method directly accepts a list of image paths.
        # Therefore, this preprocessing step simply passes the list of paths through.
        # No image loading or tensor conversion is needed here.
        return input_images

    def predict(self, model_input):
        # model_input is a list of image paths from the preprocess step.
        # The predict method handles batching via its batch_size argument.
        # We use the length of the input list as the batch size to process all images at once.
        return self.model.predict(model_input, threshold=self.threshold, batch_size=len(model_input))

    def postprocess(self, model_output):
        # The model_output is a list of paddleocr StructureResult objects.
        # We will format the result dictionary of each object into a JSON string.
        # This makes the output a list of strings, adapting the object detection output to the expected text format.
        preds = []
        for result_object in model_output:
            if hasattr(result_object, 'res') and isinstance(result_object.res, dict):
                preds.append(json.dumps(result_object.res))
            else:
                # Handle cases where the output might not be the expected StructureResult object
                preds.append(json.dumps(str(result_object)))
        return preds
