# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
from open_clip import create_model_from_pretrained, get_tokenizer

class PyTorch_Custom_BiomedCLIP(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False) # multi_gpu not supported by open_clip loading, but kept for compatibility

        model_id = 'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'

        self.model, self.preprocess_fn = create_model_from_pretrained(model_id)
        self.tokenizer = get_tokenizer(model_id)

        self.model.to(device)
        self.model.eval()

        # Default labels from model card, can be overridden in config
        default_labels = [
            'adenocarcinoma histopathology',
            'brain MRI',
            'covid line chart',
            'squamous cell carcinoma histopathology',
            'immunohistochemistry histopathology',
            'bone X-ray',
            'chest X-ray',
            'pie chart',
            'hematoxylin and eosin histopathology'
        ]
        self.labels = self.config.get("labels", default_labels)
        self.template = self.config.get("template", "this is a photo of ")
        self.context_length = 256

        # Pre-tokenize the text labels for efficiency
        self.text_tokens = self.tokenizer([self.template + l for l in self.labels], context_length=self.context_length).to(device)

    def preprocess(self, input_images):
        processed_images = []
        for image_path in input_images:
            image = Image.open(image_path).convert("RGB")
            processed_images.append(self.preprocess_fn(image))
        
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        image_tensor = model_input.to(self.model.device)
        with torch.no_grad():
            image_features, text_features, logit_scale = self.model(image_tensor, self.text_tokens)
            logits = (logit_scale * image_features @ text_features.t())
        return logits

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=1)
        return probabilities.tolist()
