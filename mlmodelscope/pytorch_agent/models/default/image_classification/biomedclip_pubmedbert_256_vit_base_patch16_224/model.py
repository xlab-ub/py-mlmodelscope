# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
from open_clip import create_model_from_pretrained, get_tokenizer

class PyTorch_OpenCLIP_BiomedCLIP_PubMedBERT_vit_base_patch16_224(PyTorchAbstractClass):
    def __init__(self, config=None):
        super().__init__(config)
        model_id = 'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'

        self.model, self.preprocessor = create_model_from_pretrained(model_id)
        self.tokenizer = get_tokenizer(model_id)
        self.model.to(self.device)
        self.model.eval()

        if not (config and 'labels' in config and isinstance(config['labels'], list) and config['labels']):
            raise ValueError("Configuration must include a 'labels' key with a non-empty list of class names for this zero-shot model.")
        self.labels = config['labels']

        template = 'this is a photo of '
        text_descriptions = [template + label for label in self.labels]
        text_tokens = self.tokenizer(text_descriptions, context_length=256).to(self.device)

        with torch.no_grad():
            self.text_features = self.model.encode_text(text_tokens)
            self.text_features /= self.text_features.norm(dim=-1, keepdim=True)

    def preprocess(self, input_images):
        processed_images = [
            self.preprocessor(Image.open(image_path).convert('RGB'))
            for image_path in input_images
        ]
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        images = model_input.to(self.device)
        with torch.no_grad():
            image_features = self.model.encode_image(images)
            image_features /= image_features.norm(dim=-1, keepdim=True)
            logit_scale = self.model.logit_scale.exp()
            logits = logit_scale * image_features @ self.text_features.t()
        return logits

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=1)
        return probabilities.tolist()
