# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
import open_clip
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_OpenCLIP_ViT_B_32_DataCompXL(PyTorchAbstractClass):
    def __init__(self, config=None):
        model_id = "laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K"
        # This model uses the open_clip library
        self.model, _, self.image_processor = open_clip.create_model_and_transforms(
            'ViT-B-32',
            pretrained=f'hf-hub:{model_id}'
        )
        self.tokenizer = open_clip.get_tokenizer('ViT-B-32')
        self.model.eval()

        # Download ImageNet classes for zero-shot classification
        features_file_url = "http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt"
        self.features = self.features_download(features_file_url)

        # Pre-compute text features for the classes
        text_descriptions = [f"a photo of a {label}" for label in self.features]
        text_tokens = self.tokenizer(text_descriptions)

        with torch.no_grad():
            self.text_features = self.model.encode_text(text_tokens)
            self.text_features /= self.text_features.norm(dim=-1, keepdim=True)

    def preprocess(self, input_images):
        processed_images = [
            self.image_processor(Image.open(image_path).convert("RGB"))
            for image_path in input_images
        ]
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        with torch.no_grad():
            image_features = self.model.encode_image(model_input)
            image_features /= image_features.norm(dim=-1, keepdim=True)
            # Calculate similarity between image and pre-computed text features
            # The result is the logits for each class
            model_output = (100.0 * image_features @ self.text_features.T)
        return model_output

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=1)
        return probabilities.tolist()
