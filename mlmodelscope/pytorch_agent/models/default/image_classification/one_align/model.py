# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from transformers import AutoModelForCausalLM
from PIL import Image
import torch

class PyTorch_Transformers_QFuture_OneAlign(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        model_id = "q-future/one-align"

        if multi_gpu and device == "cuda":
            self.model = AutoModelForCausalLM.from_pretrained(
                model_id,
                trust_remote_code=True,
                attn_implementation="eager",
                torch_dtype=torch.float16,
                device_map="auto"
            )
        else:
            self.model = AutoModelForCausalLM.from_pretrained(
                model_id,
                trust_remote_code=True,
                attn_implementation="eager",
                torch_dtype=torch.float16
            ).to(device)

        self.model.eval()

    def preprocess(self, input_images):
        images = [Image.open(image_path).convert('RGB') for image_path in input_images]
        return images

    def predict(self, model_input):
        task = self.config.get("task", "quality")
        input_type = self.config.get("input_type", "image")
        with torch.no_grad():
            scores = self.model.score(model_input, task_=task, input_=input_type)
        return scores

    def postprocess(self, model_output):
        # The model's score method returns the final scores (e.g., a float or list of floats), not logits.
        # We just need to ensure the output is a list.
        if isinstance(model_output, (int, float)):
            return [model_output]
        elif hasattr(model_output, 'tolist'): # Handle potential tensor output
            return model_output.tolist()
        return model_output
