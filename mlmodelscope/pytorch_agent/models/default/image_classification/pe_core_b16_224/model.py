# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
# The 'perception_models' library must be installed from https://github.com/facebookresearch/perception_models.git
import core.vision_encoder.pe as pe
import core.vision_encoder.transforms as transforms

class PyTorch_PE_Core_B16_224(PyTorchAbstractClass):
    def __init__(self, config=None):
        super().__init__(config)
        model_id = "facebook/PE-Core-B16-224"

        # This is a zero-shot classification model (like CLIP) and requires text labels.
        # These labels are expected to be provided in the config's 'features_path' or 'features' list.
        if not self.features:
            raise ValueError("Text labels (features) are required for this zero-shot classification model.")

        self.model = pe.CLIP.from_config(model_id, pretrained=True)
        self.model.eval()

        self.preprocess_transform = transforms.get_image_transform(self.model.image_size)
        self.tokenizer = transforms.get_text_tokenizer(self.model.context_length)

        # Pre-tokenize the text labels for efficiency
        self.tokenized_text = self.tokenizer(self.features)

    def preprocess(self, input_images):
        processed_images = [
            self.preprocess_transform(Image.open(image_path).convert('RGB'))
            for image_path in input_images
        ]
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        # Move inputs to the same device as the model
        device = next(self.model.parameters()).device
        images = model_input.to(device)
        text = self.tokenized_text.to(device)

        with torch.no_grad():
            # The model card suggests using autocast for performance
            with torch.autocast(device_type=device.type):
                image_features, text_features, logit_scale = self.model(images, text)
                # Calculate the logits (similarity scores) before softmax
                logits = logit_scale * image_features @ text_features.T
        return logits

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=-1)
        return probabilities.tolist()
