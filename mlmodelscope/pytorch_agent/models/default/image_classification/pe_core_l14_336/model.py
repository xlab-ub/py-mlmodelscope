# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

# User must install perception_models: 
# git clone https://github.com/facebookresearch/perception_models.git
# cd perception_models
# pip install -e .
import core.vision_encoder.pe as pe
import core.vision_encoder.transforms as transforms

class PyTorch_PE_Core_L14_336(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)  # Note: multi_gpu is not supported by this custom model loader
        self.device = torch.device(device)

        model_id = "PE-Core-L14-336"
        self.model = pe.CLIP.from_config(model_id, pretrained=True).to(self.device).eval()

        self.preprocess_transform = transforms.get_image_transform(self.model.image_size)
        self.tokenizer = transforms.get_text_tokenizer(self.model.context_length)

        self.labels = self.config.get("labels")
        if not self.labels or not isinstance(self.labels, list):
            raise ValueError("Zero-shot classification requires a list of 'labels' to be provided in the config.")

        # Pre-tokenize the labels for prediction
        self.tokenized_labels = self.tokenizer(self.labels).to(self.device)

    def preprocess(self, input_images):
        processed_images = [
            self.preprocess_transform(Image.open(image_path).convert('RGB'))
            for image_path in input_images
        ]
        model_input = torch.stack(processed_images).to(self.device)
        return model_input

    def predict(self, model_input):
        with torch.no_grad():
            # The model call computes features for both the input images and the pre-tokenized labels
            image_features, text_features, logit_scale = self.model(model_input, self.tokenized_labels)
            # Return all components needed for postprocessing
            return image_features, text_features, logit_scale

    def postprocess(self, model_output):
        image_features, text_features, logit_scale = model_output
        # Calculate the cosine similarity and apply the learned logit scale
        logits_per_image = logit_scale * image_features @ text_features.T
        probabilities = logits_per_image.softmax(dim=-1)
        return probabilities.cpu().tolist()
