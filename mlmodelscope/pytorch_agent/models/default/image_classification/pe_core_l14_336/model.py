# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
import os
import sys
import subprocess

class PyTorch_PE_Core_L14_336(PyTorchAbstractClass):
    def __init__(self, config=None):
        super().__init__(config)
        repo_url = "https://github.com/facebookresearch/perception_models.git"
        repo_dir = "perception_models"

        if not os.path.exists(repo_dir):
            try:
                print(f"Cloning repository: {repo_url}")
                subprocess.run(["git", "clone", repo_url], check=True, capture_output=True, text=True)
            except subprocess.CalledProcessError as e:
                raise RuntimeError(f"Failed to clone repository: {e}\nSTDOUT: {e.stdout}\nSTDERR: {e.stderr}")

        # Add the cloned repo to the Python path
        sys.path.insert(0, os.path.abspath(repo_dir))

        try:
            import core.vision_encoder.pe as pe
            import core.vision_encoder.transforms as transforms
        except ImportError as e:
            raise ImportError(f"Failed to import from the cloned repository. Error: {e}")

        model_id = "PE-Core-L14-336"
        self.model = pe.CLIP.from_config(model_id, pretrained=True)
        self.model.to(self.device)
        self.model.eval()

        self.image_transform = transforms.get_image_transform(self.model.image_size)
        self.tokenizer = transforms.get_text_tokenizer(self.model.context_length)

    def preprocess(self, input_images):
        processed_images = []
        for image_path in input_images:
            image = Image.open(image_path).convert("RGB")
            processed_image = self.image_transform(image)
            processed_images.append(processed_image)
        
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        if not predict_config or 'labels' not in predict_config:
            raise ValueError("This model requires a list of 'labels' in predict_config for zero-shot classification.")
        
        labels = predict_config['labels']
        
        image_tensor = model_input.to(self.device)
        text_tokens = self.tokenizer(labels).to(self.device)
        
        with torch.no_grad():
            image_features, text_features, logit_scale = self.model(image_tensor, text_tokens)
            # The model card shows using autocast, which is good practice for performance
            # with torch.autocast("cuda"):
            #     image_features, text_features, logit_scale = self.model(image_tensor, text_tokens)
            logits = logit_scale * image_features @ text_features.T
            
        return logits

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=-1)
        return probabilities.tolist()
