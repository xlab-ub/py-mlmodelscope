# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from transformers import AutoProcessor, AutoModel
from PIL import Image

class PyTorch_Transformers_PickScore_v1(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False) # Note: multi_gpu not directly used due to custom logic

        processor_id = "laion/CLIP-ViT-H-14-laion2B-s32B-b79K"
        model_id = "yuvalkirstain/PickScore_v1"

        self.processor = AutoProcessor.from_pretrained(processor_id)
        self.model = AutoModel.from_pretrained(model_id)

        self.model.to(device)
        self.model.eval()
        self.device = device

    def preprocess(self, input_images):
        # The model requires both image and text (prompt) for prediction.
        # Preprocessing will just load the images. The prompt is passed via options to the predict method.
        processed_images = [
            Image.open(image_path).convert('RGB')
            for image_path in input_images
        ]
        return processed_images

    def predict(self, model_input):
        # model_input is a list of PIL images from preprocess
        # The prompt is expected in the options dictionary
        prompt = options.get("prompt")
        if not prompt:
            raise ValueError("A 'prompt' must be provided in the options dictionary for PickScore model.")

        # Preprocess image and text inputs
        image_inputs = self.processor(
            images=model_input,
            padding=True,
            truncation=True,
            max_length=77,
            return_tensors="pt",
        ).to(self.device)
        
        text_inputs = self.processor(
            text=prompt,
            padding=True,
            truncation=True,
            max_length=77,
            return_tensors="pt",
        ).to(self.device)

        with torch.no_grad():
            # Embed image and text
            image_embs = self.model.get_image_features(**image_inputs)
            image_embs = image_embs / torch.norm(image_embs, dim=-1, keepdim=True)
        
            text_embs = self.model.get_text_features(**text_inputs)
            text_embs = text_embs / torch.norm(text_embs, dim=-1, keepdim=True)
        
            # Calculate scores
            scores = self.model.logit_scale.exp() * (text_embs @ image_embs.T)[0]
            
        return scores

    def postprocess(self, model_output):
        # model_output is the raw scores tensor
        probabilities = torch.softmax(model_output, dim=-1)
        return probabilities.cpu().tolist()
