# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoProcessor, AutoModel
from PIL import Image
import torch

class PyTorch_Transformers_PickScore_v1(PyTorchAbstractClass):
    def __init__(self, config=None):
        super().__init__(config)
        processor_id = "laion/CLIP-ViT-H-14-laion2B-s32B-b79K"
        model_id = "yuvalkirstain/PickScore_v1"

        self.processor = AutoProcessor.from_pretrained(processor_id)
        self.model = self.load_hf_model(AutoModel, model_id)
        self.model.eval()

        # The model requires a text prompt. This can be set via the config dictionary.
        # A default prompt is used if none is provided.
        default_prompt = "a high quality, good photo"
        self.prompt = default_prompt if config is None else config.get("prompt", default_prompt)

    def preprocess(self, input_images):
        pil_images = [Image.open(image_path).convert("RGB") for image_path in input_images]
        model_input = self.processor(
            images=pil_images,
            padding=True,
            truncation=True,
            max_length=77,
            return_tensors="pt",
        )
        return model_input

    def predict(self, model_input):
        # Move image inputs to the correct device
        image_inputs = {k: v.to(self.device) for k, v in model_input.items()}

        # Process the text prompt
        text_inputs = self.processor(
            text=self.prompt,
            padding=True,
            truncation=True,
            max_length=77,
            return_tensors="pt",
        ).to(self.device)

        with torch.no_grad():
            # Embed images
            image_embs = self.model.get_image_features(**image_inputs)
            image_embs = image_embs / torch.norm(image_embs, dim=-1, keepdim=True)

            # Embed text
            text_embs = self.model.get_text_features(**text_inputs)
            text_embs = text_embs / torch.norm(text_embs, dim=-1, keepdim=True)

            # Calculate scores
            scores = self.model.logit_scale.exp() * (text_embs @ image_embs.T)[0]

        return scores

    def postprocess(self, model_output):
        probabilities = torch.nn.functional.softmax(model_output, dim=-1)
        return probabilities.cpu().tolist()
