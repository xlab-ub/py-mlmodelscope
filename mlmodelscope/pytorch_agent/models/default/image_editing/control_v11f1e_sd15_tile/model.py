# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from diffusers import StableDiffusionControlNetImg2ImgPipeline, ControlNetModel, UniPCMultistepScheduler
from PIL import Image
import numpy as np
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Diffusers_ControlNetTile(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")

        controlnet_model_id = "lllyasviel/control_v11f1e_sd15_tile"
        base_model_id = "runwayml/stable-diffusion-v1-5"

        torch_dtype = torch.float16 if device == "cuda" else torch.float32

        controlnet = ControlNetModel.from_pretrained(controlnet_model_id, torch_dtype=torch_dtype)
        
        self.pipeline = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(
            base_model_id,
            controlnet=controlnet,
            torch_dtype=torch_dtype,
            safety_checker=None
        )
        
        self.pipeline.scheduler = UniPCMultistepScheduler.from_config(self.pipeline.scheduler.config)
        
        self.seed = self.config.get('seed', 0)
        self.generator = None

    def preprocess(self, input_images_and_prompts):
        def resize_for_condition_image(input_image: Image.Image, resolution: int):
            input_image = input_image.convert("RGB")
            W, H = input_image.size
            k = float(resolution) / min(H, W)
            H = int(round(H * k))
            W = int(round(W * k))
            # Ensure dimensions are divisible by 64
            H = int(round(H / 64.0)) * 64
            W = int(round(W / 64.0)) * 64
            img = input_image.resize((W, H), resample=Image.LANCZOS)
            return img

        images = []
        prompts = []
        negative_prompts = []
        
        default_prompt = "best quality, extremely detailed"
        default_negative_prompt = "blur, lowres, bad anatomy, bad hands, cropped, worst quality"
        
        for item in input_images_and_prompts:
            if isinstance(item, str):
                img_path, prompt_dict = item, {}
            else:
                img_path, prompt_dict = item

            image = Image.open(img_path).convert("RGB")
            resolution = self.config.get("resolution", 1024)
            processed_image = resize_for_condition_image(image, resolution)
            images.append(processed_image)
            
            prompts.append(prompt_dict.get("prompt", default_prompt))
            negative_prompts.append(prompt_dict.get("negative_prompt", default_negative_prompt))

        return {
            "prompt": prompts,
            "negative_prompt": negative_prompts,
            "image": images,
            "control_image": images,
            "generator": self.generator,
            "num_inference_steps": self.config.get("num_inference_steps", 32)
        }

    def predict(self, model_input):
        return self.pipeline(**model_input).images

    def postprocess(self, model_output):
        return [np.array(img).tolist() for img in model_output]

    def to(self, device):
        self.device = device
        self.pipeline.to(device)
        try:
            self.pipeline.enable_xformers_memory_efficient_attention()
        except (ImportError, Exception):
            print("xformers is not installed, proceeding without it")
        self.generator = torch.Generator(device=device).manual_seed(self.seed)

    def eval(self):
        pass
