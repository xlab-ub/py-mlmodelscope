# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
import numpy as np
from PIL import Image
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from medvae import MVAE

class PyTorch_Custom_MedVAE(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # Note: multi_gpu not directly supported by the MVAE library's loading mechanism
        multi_gpu = self.config.pop("_multi_gpu", False)

        # Default model configuration, can be overridden by providing 'model_name' and 'modality' in config
        # 'stanfordmimi/MedVAE' is the source repo, which the 'medvae' library uses implicitly
        model_name = self.config.get("model_name", "medvae_4_3_2d")
        modality = self.config.get("modality", "xray")

        self.model = MVAE(model_name=model_name, modality=modality)

    def preprocess(self, input_images):
        # The model's transform method processes images from file paths
        processed_images = [self.model.apply_transform(img_path) for img_path in input_images]
        images_tensor = torch.stack(processed_images)
        return {"images": images_tensor}

    def predict(self, model_input):
        images = model_input["images"].to(self.device)
        with torch.no_grad():
            # The forward pass of the VAE performs encoding and decoding to reconstruct the image
            reconstructed_images = self.model(images)
        return reconstructed_images

    def postprocess(self, model_output):
        # The output is a tensor of reconstructed images, likely in the range [-1, 1]
        images = model_output.cpu()
        # Normalize to [0, 1]
        images = (images / 2 + 0.5).clamp(0, 1)
        # Scale to [0, 255] and convert to uint8
        images = (images * 255).round().to(torch.uint8)
        # Permute from (B, C, H, W) to (B, H, W, C) for standard image format
        images = images.permute(0, 2, 3, 1)
        # Handle single-channel (grayscale) images which might have a channel dim of 1
        if images.shape[-1] == 1:
            images = images.squeeze(-1)
        return [img.numpy().tolist() for img in images]

    def to(self, device):
        self.device = device
        self.model.to(device)

    def eval(self):
        self.model.requires_grad_(False)
        self.model.eval()
