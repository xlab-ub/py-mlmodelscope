# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
import torch
from diffusers import FluxInpaintPipeline
from PIL import Image
import numpy as np

class PyTorch_Diffusers_FluxInpaint(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        # device and multi_gpu are handled in the `to` method for pipelines
        self.config.pop("_device", "cpu")
        self.config.pop("_multi_gpu", False)

        model_id = "nunchaku-tech/nunchaku-flux.1-fill-dev"
        # This model is a quantized version of FLUX.1-Fill-dev, which uses the FluxInpaintPipeline
        self.pipeline = FluxInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.bfloat16
        )
        self.seed = self.config.pop('seed', 0)
        self.generator = torch.Generator(device="cpu").manual_seed(self.seed)

    def preprocess(self, input_data):
        # input_data is expected to be a list of dictionaries, 
        # where each dictionary has 'image_path', 'mask_path', and 'prompt'.
        prompts = []
        images = []
        mask_images = []
        for item in input_data:
            prompts.append(item['prompt'])
            images.append(Image.open(item['image_path']).convert("RGB"))
            mask_images.append(Image.open(item['mask_path']).convert("RGB"))

        # Pass generator and any other pipeline-specific parameters from the config
        return {
            "prompt": prompts,
            "image": images,
            "mask_image": mask_images,
            "generator": self.generator,
            **self.config
        }

    def predict(self, model_input):
        return self.pipeline(**model_input).images

    def postprocess(self, model_output):
        # The pipeline output is a list of PIL images
        return [np.array(img).tolist() for img in model_output]

    def to(self, device):
        self.device = device
        self.pipeline.to(device)
        self.generator = torch.Generator(device=device).manual_seed(self.seed)

    def eval(self):
        # Diffusers pipelines are in eval mode by default.
        pass
