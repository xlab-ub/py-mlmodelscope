# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from diffusers import QwenImageControlNetPipeline, QwenImageControlNetModel
from PIL import Image
import numpy as np
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Diffusers_QwenImageControlNet(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        # This model does not support multi_gpu device_map, it will be moved to a device in the to() method
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        base_model = "Qwen/Qwen-Image"
        controlnet_model = "InstantX/Qwen-Image-ControlNet-Union"

        controlnet = QwenImageControlNetModel.from_pretrained(controlnet_model, torch_dtype=torch.bfloat16)
        self.pipeline = QwenImageControlNetPipeline.from_pretrained(
            base_model, controlnet=controlnet, torch_dtype=torch.bfloat16
        )
        self.seed = self.config.get('seed', 42)

    def preprocess(self, input_images_and_prompts):
        images = []
        prompts = []
        for img_path, prompt in input_images_and_prompts:
            images.append(Image.open(img_path).convert('RGB'))
            prompts.append(prompt)
        return {"control_image": images, "prompt": prompts}

    def predict(self, model_input):
        control_images = model_input.pop("control_image")
        prompts = model_input.pop("prompt")

        # Use the dimensions of the first control image for the output
        first_image = control_images[0]

        params = {
            "negative_prompt": self.config.get("negative_prompt", " "),
            "width": self.config.get("width", first_image.size[0]),
            "height": self.config.get("height", first_image.size[1]),
            "num_inference_steps": self.config.get("num_inference_steps", 30),
            "controlnet_conditioning_scale": self.config.get("controlnet_conditioning_scale", 1.0),
            "true_cfg_scale": self.config.get("true_cfg_scale", 4.0),
            "generator": self.generator
        }

        return self.pipeline(prompt=prompts, control_image=control_images, **params).images

    def postprocess(self, model_output):
        # The pipeline output is a list of PIL images
        return [np.array(img).tolist() for img in model_output]

    def to(self, device):
        self.device = device
        self.pipeline.to(device)
        self.generator = torch.Generator(device=device).manual_seed(self.seed)

    def eval(self):
        # Diffusers pipelines manage their own model modes.
        pass

