# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from diffusers import DiffusionPipeline
from PIL import Image
import numpy as np
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Diffusers_StableDelight(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        model_id = "Stable-X/yoso-delight-v0-4-base"
        
        # trust_remote_code is required to load the custom YOSODiffusePipeline from the model repository
        self.pipeline = DiffusionPipeline.from_pretrained(
            model_id, 
            torch_dtype=torch.float16, 
            trust_remote_code=True
        )

    def preprocess(self, input_images):
        images = [Image.open(img_path).convert('RGB') for img_path in input_images]
        # The custom pipeline expects the 'image' argument
        return {"image": images}

    def predict(self, model_input):
        # The pipeline returns an object with an 'images' attribute containing the output PIL images
        return self.pipeline(**model_input).images

    def postprocess(self, model_output):
        # The model output is a list of PIL images, convert them to numpy arrays and then to lists for JSON serialization
        return [np.array(img).tolist() for img in model_output]

    def to(self, device):
        self.device = device
        self.pipeline.to(device)

    def eval(self):
        # Pipelines are typically in eval mode by default and do not need a separate call.
        pass

