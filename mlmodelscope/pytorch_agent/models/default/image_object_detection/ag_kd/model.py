# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoProcessor, AutoModel
from PIL import Image
import torch
import re
import warnings

class PyTorch_Transformers_RioJune_AGKD(PyTorchAbstractClass):
    def __init__(self):
        super().__init__(config)
        warnings.warn("This model processes one image at a time. The batch size should be 1.")
        model_id = "RioJune/AG-KD"
        self.processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
        self.model = self.load_hf_model(AutoModel, model_id, trust_remote_code=True)

    def preprocess(self, input_images):
        # This model is a generative model that requires a text prompt along with the image.
        # Since the interface only provides images, we use a hardcoded prompt for lesion detection.
        instruction = "<OD> Please localize the lesion."
        
        # The model's example processes one image at a time.
        image = Image.open(input_images[0]).convert("RGB")
        
        model_input = self.processor(images=image, text=instruction, return_tensors="pt")
        model_input = {k: v.to(self.device) for k, v in model_input.items()}
        return model_input

    def predict(self, model_input):
        # This is a generative model, so we call `generate` instead of a standard forward pass.
        with torch.no_grad():
            return self.model.generate(
                input_ids=model_input["input_ids"],
                pixel_values=model_input["pixel_values"],
                max_new_tokens=1024,
                num_beams=3
            )

    def postprocess(self, model_output):
        # Decode the generated token IDs to a text string.
        output_text = self.processor.batch_decode(model_output, skip_special_tokens=False)[0]

        scores = []
        labels = []
        boxes = []

        # The model outputs bounding boxes as special tokens, e.g., <loc_123><loc_456><loc_789><loc_012>.
        # We use regex to find all such patterns in the output text.
        # The coordinates are quantized into 1000 bins (0-999), so we normalize by dividing by 999.0.
        pattern = re.compile(r"<loc_(\\d{3})><loc_(\\d{3})><loc_(\\d{3})><loc_(\\d{3})>")
        matches = pattern.findall(output_text)

        for match in matches:
            # Convert string coordinates to normalized float coordinates [x1, y1, x2, y2].
            box = [int(p) / 999.0 for p in match]
            boxes.append(box)
            
            # The model does not provide confidence scores or class labels.
            # We return a dummy score of 1.0 and a dummy label of 1.
            scores.append(1.0)
            labels.append(1) # Label 1 corresponds to "lesion" from the hardcoded prompt.

        return [scores], [labels], [boxes]
