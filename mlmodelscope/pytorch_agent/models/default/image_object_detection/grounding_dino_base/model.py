# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from PIL import Image
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Transformers_GroundingDinoBase(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)
        self.device = device

        model_id = "thoddnn/grounding-dino-base"

        self.processor = AutoProcessor.from_pretrained(model_id)

        if multi_gpu and device == "cuda":
            self.model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id, device_map="auto", torch_dtype="auto")
        else:
            self.model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id)
            self.model.to(self.device)

    def preprocess(self, input_images):
        predict_config = predict_config if predict_config else {}
        text_queries = predict_config.get("text_queries")
        if not text_queries:
            raise ValueError("predict_config must contain 'text_queries' for this model (e.g., 'a cat. a remote control.')")

        images = [Image.open(img_path).convert("RGB") for img_path in input_images]

        if isinstance(text_queries, str):
            text_input = [text_queries] * len(images)
        elif isinstance(text_queries, list) and len(text_queries) == len(images):
            text_input = text_queries
        else:
            raise ValueError("'text_queries' must be a string or a list of strings matching the number of images.")

        model_input = self.processor(images=images, text=text_input, return_tensors="pt")

        # Store context for postprocessing
        self.input_ids = model_input.input_ids
        self.target_sizes = torch.tensor([img.size[::-1] for img in images])

        return model_input

    def predict(self, model_input):
        model_input = {k: v.to(self.device) for k, v in model_input.items()}
        with torch.no_grad():
            return self.model(**model_input)

    def postprocess(self, model_output):
        predict_config = predict_config if predict_config else {}
        box_threshold = predict_config.get("box_threshold", 0.4)
        text_threshold = predict_config.get("text_threshold", 0.3)

        results = self.processor.post_process_grounded_object_detection(
            model_output,
            input_ids=self.input_ids,
            box_threshold=box_threshold,
            text_threshold=text_threshold,
            target_sizes=self.target_sizes
        )

        # Assuming batch size is 1
        result = results[0]
        scores = result['scores'].tolist()
        labels = result['labels']  # List of strings
        boxes = result['boxes'].tolist()

        return [scores], [labels], [boxes]
