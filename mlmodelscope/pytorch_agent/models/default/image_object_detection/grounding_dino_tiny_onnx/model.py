# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from PIL import Image
import torch

class PyTorch_Transformers_GroundingDinoTinyONNX(PyTorchAbstractClass):
    def __init__(self):
        super().__init__(config)
        model_id = "onnx-community/grounding-dino-tiny-ONNX"
        self.processor = AutoProcessor.from_pretrained(model_id)
        self.model = self.load_hf_model(AutoModelForZeroShotObjectDetection, model_id)
        # Hardcoded text prompt for zero-shot detection, as the preprocess interface only accepts images.
        # This can be customized for different detection tasks.
        self.text_prompt = "a cat. a remote control. a couch."

    def preprocess(self, input_images):
        pil_images = [Image.open(p).convert("RGB") for p in input_images]
        # Save target sizes and input_ids for post-processing, assuming batch size is 1.
        self.target_sizes = torch.tensor([img.size[::-1] for img in pil_images])
        model_input = self.processor(images=pil_images, text=self.text_prompt, return_tensors="pt")
        self.input_ids = model_input['input_ids']
        return model_input

    def predict(self, model_input):
        return self.model(**model_input)

    def postprocess(self, model_output):
        # The processor needs the original image sizes and input_ids for post-processing,
        # which were saved in the preprocess step.
        results = self.processor.post_process_grounded_object_detection(
            outputs=model_output,
            input_ids=self.input_ids,
            target_sizes=self.target_sizes,
            box_threshold=0.4,
            text_threshold=0.3
        )

        # Assuming batch size is 1, get the results for the first image.
        result = results[0]
        scores = result['scores']
        labels = result['labels']  # These are string labels
        boxes = result['boxes']

        # The expected output is a tuple of lists, where each list contains results for one image.
        return [scores], [labels], [boxes]
