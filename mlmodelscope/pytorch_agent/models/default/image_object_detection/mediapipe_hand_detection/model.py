# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
import warnings
from qai_hub_models.models.mediapipe_hand import Model
from torchvision import transforms

class PyTorch_Qualcomm_MediaPipe_Hand_Detection(PyTorchAbstractClass):
    def __init__(self):
        warnings.warn("The batch size should be 1.")
        # Model: qualcomm/MediaPipe-Hand-Detection
        self.model = Model.from_pretrained()
        self.model.eval()

    def preprocess(self, input_images):
        preprocessor = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.ToTensor(),
        ])
        images = [preprocessor(Image.open(img_path).convert("RGB")) for img_path in input_images]
        model_input = torch.stack(images)
        return model_input

    def predict(self, model_input):
        return self.model(model_input)

    def postprocess(self, model_output):
        return [model_output[0]['scores'].tolist()], [model_output[0]['labels'].tolist()], [model_output[0]['boxes'].tolist()]
