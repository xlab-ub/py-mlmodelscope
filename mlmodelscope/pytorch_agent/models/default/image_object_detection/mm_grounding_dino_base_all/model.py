# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from PIL import Image
import torch

class PyTorch_Transformers_MMGroundingDinoBaseAll(PyTorchAbstractClass):
    def __init__(self):
        super().__init__(config)
        model_id = 'openmmlab-community/mm_grounding_dino_base_all'
        self.processor = AutoProcessor.from_pretrained(model_id)
        self.load_hf_model(AutoModelForZeroShotObjectDetection, model_id)

    def preprocess(self, input_images):
        if 'text_labels' not in kwargs:
            raise ValueError("This model requires 'text_labels' to be provided in kwargs during preprocessing. Example: text_labels=[['a cat', 'a remote control']]")

        images = []
        self.original_sizes = []
        for img_path in input_images:
            img = Image.open(img_path).convert("RGB")
            images.append(img)
            self.original_sizes.append(img.size) # Store (width, height)

        model_input = self.processor(images=images, text=kwargs['text_labels'], return_tensors="pt")
        return model_input

    def predict(self, model_input):
        return self.model(**model_input)

    def postprocess(self, model_output):
        # The processor expects target sizes as (height, width)
        target_sizes = torch.tensor([size[::-1] for size in self.original_sizes])
        
        results = self.processor.post_process_grounded_object_detection(
            model_output,
            threshold=0.4, # Using a default threshold
            target_sizes=target_sizes
        )
        
        # Assuming batch size is 1
        result = results[0]
        
        scores = result["scores"].tolist()
        labels = result["labels"] # These are string labels, not class indices
        boxes = result["boxes"].tolist()
        
        return [scores], [labels], [boxes]
