# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
from PIL import Image
import torch

class PyTorch_Transformers_MMGroundingDinoLargeAll(PyTorchAbstractClass):
    def __init__(self{"model_id": "openmmlab-community/mm_grounding_dino_large_all"}):
        super().__init__(config)
        self.processor = AutoProcessor.from_pretrained(self.model_id)
        self.load_hf_model(AutoModelForZeroShotObjectDetection, self.model_id)

    def preprocess(self, input_images):
        images = []
        self.target_sizes = []
        for image_path in input_images:
            image = Image.open(image_path).convert("RGB")
            images.append(image)
            self.target_sizes.append(image.size[::-1])
        text = predict_args.get("text_labels", [["a cat", "a remote control"]])
        model_input = self.processor(images=images, text=text, return_tensors="pt")
        return model_input

    def predict(self, model_input):
        return self.model(**model_input)

    def postprocess(self, model_output):
        target_sizes = torch.tensor(self.target_sizes)
        results = self.processor.post_process_grounded_object_detection(
            model_output,
            threshold=0.4,
            target_sizes=target_sizes
        )
        result = results[0]
        scores = result["scores"].tolist()
        labels = result["labels"]
        boxes = result["boxes"].tolist()
        return [scores], [labels], [boxes]
