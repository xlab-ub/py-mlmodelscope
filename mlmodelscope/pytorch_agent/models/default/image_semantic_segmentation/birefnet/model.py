# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from transformers import AutoModelForImageSegmentation
from PIL import Image
import torch
from torchvision import transforms

class PyTorch_Transformers_ZhengPeng7_BiRefNet(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)
        model_id = 'ZhengPeng7/BiRefNet'

        if multi_gpu and device == "cuda":
            self.model = AutoModelForImageSegmentation.from_pretrained(model_id, trust_remote_code=True, device_map="auto", torch_dtype="auto")
        else:
            self.model = AutoModelForImageSegmentation.from_pretrained(model_id, trust_remote_code=True)

        image_size = (1024, 1024)
        self.transform = transforms.Compose([
            transforms.Resize(image_size),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def preprocess(self, input_images):
        processed_images = []
        for img_path in input_images:
            image = Image.open(img_path).convert("RGB")
            processed_images.append(self.transform(image))
        model_input = torch.stack(processed_images)
        return model_input

    def predict(self, model_input):
        return self.model(pixel_values=model_input)

    def postprocess(self, model_output):
        # The model returns a tuple, and the segmentation map is the last element.
        segmentation_maps = model_output[-1].sigmoid()
        # Apply a threshold to get a binary mask
        binary_masks = (segmentation_maps > 0.5).int()
        # Squeeze the channel dimension and convert to list
        return binary_masks.squeeze(1).tolist()
