# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from PIL import Image
import torchvision.transforms as transforms
import warnings
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Hub_BiRefNet_Matting(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        warnings.warn("If the size of the images is not consistent, the batch size should be 1.")
        # Note: Custom models from torch.hub do not typically support device_map
        self.model = torch.hub.load('ZhengPeng7/BiRefNet-matting', 'BiRefNet_matting', pretrained=True, trust_repo=True)
        self.model.eval()
        self.model.to(device)
        self.device = device

        self.preprocessor = transforms.Compose([
            transforms.Resize((320, 320)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

    def preprocess(self, input_images):
        processed_images = []
        for img_path in input_images:
            img = Image.open(img_path).convert('RGB')
            processed_images.append(self.preprocessor(img))
        model_input = torch.stack(processed_images).to(self.device)
        return model_input

    def predict(self, model_input):
        with torch.no_grad():
            return self.model(model_input)

    def postprocess(self, model_output):
        # The model returns a tuple of outputs, the first one is the main prediction
        # The output is an alpha matte (a soft mask), not class indices, so no argmax is needed.
        # The shape is (batch_size, 1, height, width)
        return model_output[0].squeeze(1).cpu().tolist()
