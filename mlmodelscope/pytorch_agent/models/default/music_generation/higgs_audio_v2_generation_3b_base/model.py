# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from boson_multimodal.serve.serve_engine import HiggsAudioServeEngine
from boson_multimodal.data_types import ChatMLSample, Message
import torch

class PyTorch_BosonAI_HiggsAudioV2(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False) # Note: HiggsAudioServeEngine does not support device_map='auto'

        model_id = "bosonai/higgs-audio-v2-generation-3B-base"
        tokenizer_id = "bosonai/higgs-audio-v2-tokenizer"

        self.serve_engine = HiggsAudioServeEngine(model_id, tokenizer_id, device=device)

        self.system_prompt = self.config.get("system_prompt", "Generate audio following instruction.\n\n<|scene_desc_start|>\nAudio is recorded from a quiet room.\n<|scene_desc_end|>")
        self.max_new_tokens = self.config.get('max_new_tokens', 1024)
        self.temperature = self.config.get('temperature', 0.3)
        self.top_p = self.config.get('top_p', 0.95)
        self.top_k = self.config.get('top_k', 50)

        # The model card states it was trained on 24 kHz data.
        self.features = {"sampling_rate": 24000}

    def preprocess(self, input_texts):
        chat_ml_samples = []
        for text in input_texts:
            messages = [
                Message(role="system", content=self.system_prompt),
                Message(role="user", content=text),
            ]
            chat_ml_samples.append(ChatMLSample(messages=messages))
        return chat_ml_samples

    def predict(self, model_input):
        outputs = []
        for sample in model_input:
            output = self.serve_engine.generate(
                chat_ml_sample=sample,
                max_new_tokens=self.max_new_tokens,
                temperature=self.temperature,
                top_p=self.top_p,
                top_k=self.top_k,
                stop_strings=["<|end_of_text|>", "<|eot_id|>"]
            )
            outputs.append(output.audio)
        return outputs

    def postprocess(self, model_output):
        return [audio_array.tolist() for audio_array in model_output]
