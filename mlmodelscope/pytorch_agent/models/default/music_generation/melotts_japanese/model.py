# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from melo.api import TTS
import torch

class PyTorch_MeloTTS_Japanese(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # multi_gpu is not directly used by the MeloTTS library but is kept for API consistency
        multi_gpu = self.config.pop("_multi_gpu", False)

        # The model 'myshell-ai/MeloTTS-Japanese' is loaded internally by the TTS class
        # when the language 'JP' is specified.
        self.model = TTS(language='JP', device=device)

        speaker_ids = self.model.hps.data.spk2id
        self.speaker_id = speaker_ids['JP']

        self.speed = self.config.get('speed', 1.0)

        self.features = {"sampling_rate": self.model.hps.data.sampling_rate}

    def preprocess(self, input_texts):
        # The model takes raw text strings as input
        return {"texts": input_texts}

    def predict(self, model_input):
        # The model's tts method does not support batching, so we iterate through the texts.
        audios = []
        for text in model_input["texts"]:
            # The tts method returns a torch tensor of the audio waveform
            audio_tensor = self.model.tts(text, self.speaker_id, speed=self.speed)
            audios.append(audio_tensor)
        return audios

    def postprocess(self, model_output):
        # Convert the list of torch tensors to a list of lists of floats
        return [audio.cpu().numpy().tolist() for audio in model_output]
