# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts
from huggingface_hub import hf_hub_download
import torch
import os
import json

class PyTorch_Coqui_XTTS_v1(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        # multi_gpu is not supported by this model's loading mechanism
        self.config.pop("_multi_gpu", False)

        model_id = "coqui/XTTS-v1"
        config_path = hf_hub_download(repo_id=model_id, filename="config.json")
        model_path = hf_hub_download(repo_id=model_id, filename="model.pth")

        xtts_config = XttsConfig()
        xtts_config.load_json(config_path)
        
        self.model = Xtts.init_from_config(xtts_config)
        self.model.load_checkpoint(xtts_config, checkpoint_path=model_path, eval=True)
        self.model.to(device)

        self.features = {"sampling_rate": 24000}

    def preprocess(self, input_texts):
        # Expects a list containing a single JSON string with parameters.
        # e.g., ['{"text": "Hello world.", "speaker_wav": "/path/to/speaker.wav", "language": "en"}']
        # The speaker_wav must be a local path accessible by the model.
        if not isinstance(input_texts, list) or len(input_texts) == 0:
            raise ValueError("Input must be a list of JSON strings.")
        
        params = json.loads(input_texts[0])

        if 'text' not in params or 'speaker_wav' not in params or 'language' not in params:
            raise ValueError("Input JSON must contain 'text', 'speaker_wav', and 'language' keys.")
        
        return params

    def predict(self, model_input):
        return self.model.synthesize(**model_input)

    def postprocess(self, model_output):
        # The output of synthesize is a dict, we extract the waveform tensor
        return model_output['wav'].cpu().numpy().squeeze().tolist()
