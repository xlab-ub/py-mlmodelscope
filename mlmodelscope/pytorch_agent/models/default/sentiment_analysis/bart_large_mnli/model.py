# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class PyTorch_Transformers_Bart_ZeroShot(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        model_id = "facebook/bart-large-mnli"
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)

        if multi_gpu and device == "cuda":
            self.model = AutoModelForSequenceClassification.from_pretrained(model_id, device_map="auto", torch_dtype="auto")
        else:
            self.model = AutoModelForSequenceClassification.from_pretrained(model_id)

        self.features = list(self.model.config.id2label.values())

    def preprocess(self, input_texts):
        candidate_labels = kwargs.get("candidate_labels")
        if not candidate_labels:
            raise ValueError("candidate_labels must be provided for zero-shot classification")

        hypothesis_template = kwargs.get("hypothesis_template", "This example is {}.")

        pairs = []
        for text in input_texts:
            for label in candidate_labels:
                hypothesis = hypothesis_template.format(label)
                pairs.append([text, hypothesis])

        return self.tokenizer(pairs, return_tensors="pt", padding=True, truncation="only_first")

    def predict(self, model_input):
        return self.model(**model_input).logits

    def postprocess(self, model_output):
        candidate_labels = kwargs.get("candidate_labels")
        if not candidate_labels:
            raise ValueError("candidate_labels must be provided for zero-shot classification")

        multi_label = kwargs.get("multi_label", False)
        input_texts = kwargs.get("input_texts")

        num_texts = len(input_texts)
        num_labels = len(candidate_labels)

        reshaped_logits = model_output.view(num_texts, num_labels, -1)

        results = []
        for i in range(num_texts):
            text_logits = reshaped_logits[i]
            entail_contradiction_logits = text_logits[:, [0, 2]]
            probs = torch.nn.functional.softmax(entail_contradiction_logits, dim=1)
            scores = probs[:, 1].tolist()

            if multi_label:
                final_scores = scores
            else:
                scores_tensor = torch.tensor(scores)
                final_scores = torch.nn.functional.softmax(scores_tensor, dim=0).tolist()

            sorted_results = sorted(zip(candidate_labels, final_scores), key=lambda x: x[1], reverse=True)

            result_dict = {
                "sequence": input_texts[i],
                "labels": [r[0] for r in sorted_results],
                "scores": [r[1] for r in sorted_results]
            }
            results.append(result_dict)

        return results
