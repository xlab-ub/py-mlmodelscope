# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from torch.nn.functional import softmax
from transformers import AutoProcessor, AutoModel
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Transformers_BiomedCLIP_ZeroShot(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)
        model_id = "chuhac/BiomedCLIP-vit-bert-hf"

        self.processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)

        if multi_gpu and device == "cuda":
            self.model = AutoModel.from_pretrained(model_id, trust_remote_code=True, device_map="auto", torch_dtype="auto")
        else:
            self.model = AutoModel.from_pretrained(model_id, trust_remote_code=True)

        self.features = self.config.get('candidate_labels')
        if not self.features:
            raise ValueError("Zero-shot classification requires a 'candidate_labels' list in the config.")

        # Tokenize labels once during initialization
        self.tokenized_labels = self.processor(text=self.features, return_tensors="pt", padding=True)

    def preprocess(self, input_texts):
        return self.processor(text=input_texts, return_tensors="pt", padding=True, truncation=True)

    def predict(self, model_input):
        with torch.no_grad():
            return self.model.get_text_features(**model_input)

    def postprocess(self, model_output):
        # model_output contains the embeddings for the input texts
        text_embeddings = model_output

        # Move tokenized labels to the same device as the text embeddings
        tokenized_labels_on_device = {k: v.to(text_embeddings.device) for k, v in self.tokenized_labels.items()}

        # Calculate label embeddings on the fly
        with torch.no_grad():
            label_embeddings = self.model.get_text_features(**tokenized_labels_on_device)

        # Normalize both sets of embeddings
        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)
        label_embeddings /= label_embeddings.norm(dim=-1, keepdim=True)

        # Compute cosine similarity (logits)
        # The 100.0 scaling factor is a learned parameter from CLIP training
        similarity = (100.0 * text_embeddings @ label_embeddings.T)

        # Apply softmax to get probabilities
        probs = softmax(similarity, dim=-1)

        return probs.tolist()
