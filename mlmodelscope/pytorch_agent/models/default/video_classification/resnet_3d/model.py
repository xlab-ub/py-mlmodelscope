# Generated by automation script
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

import torch
from transformers import AutoProcessor, VideoMAEForVideoClassification
import av
import numpy as np
from mlmodelscope.pytorch_agent.models.pytorch_abc import PyTorchAbstractClass

class PyTorch_Qualcomm_ResNet_3D(PyTorchAbstractClass):
    def __init__(self, config=None):
        self.config = config if config else dict()
        device = self.config.pop("_device", "cpu")
        multi_gpu = self.config.pop("_multi_gpu", False)

        model_id = "qualcomm/ResNet-3D"
        # NOTE: This model is not a standard Hugging Face transformers model.
        # The following lines use a standard video classification architecture as a placeholder
        # to adhere to the required structure, but they will fail to load this specific model.
        # A custom implementation would be needed to load the ONNX/TFLite files provided in the repo.
        try:
            self.processor = AutoProcessor.from_pretrained(model_id)
            if multi_gpu and device == "cuda":
                self.model = VideoMAEForVideoClassification.from_pretrained(model_id, device_map="auto", torch_dtype="auto")
            else:
                self.model = VideoMAEForVideoClassification.from_pretrained(model_id)
            self.features = [v for k, v in sorted(self.model.config.id2label.items())]
        except Exception as e:
            # Since the model is not a transformers model, we create placeholders.
            # This allows the class to be instantiated, but predict will not work.
            print(f"Could not load model {model_id} from Hugging Face Hub using transformers: {e}")
            print("Using placeholder attributes.")
            self.processor = None
            self.model = None
            # Placeholder for Kinetics-400, which is the dataset mentioned.
            self.features = ["placeholder_class_1", "placeholder_class_2"]

    def preprocess(self, input_videos):
        if not self.processor:
            raise NotImplementedError("Model could not be loaded, preprocessing is not available.")

        container = av.open(input_videos[0])
        indices = self._sample_frame_indices(clip_len=16, frame_sample_rate=1, seg_len=container.streams.video[0].frames)
        video = self._read_video_pyav(container, indices)
        pixel_values = self.processor(videos=list(video), return_tensors="pt").pixel_values
        return pixel_values

    def predict(self, model_input):
        if not self.model:
            raise NotImplementedError("Model could not be loaded, prediction is not available.")
        return self.model(model_input)

    def postprocess(self, model_output):
        if model_output is None:
            raise ValueError("Model output is None, cannot postprocess.")
        return torch.nn.functional.softmax(model_output.logits, dim=1).tolist()
